{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8619894,"sourceType":"datasetVersion","datasetId":5159673}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport pandas as pd\ndata = pd.read_csv('/kaggle/input/stock-data/stock_data.csv')\ndata = data[['Date','AMZN']]\ndata['Date'] = pd.to_datetime(data['Date'])\ndata.set_index('Date', inplace=True)\ndata\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T06:48:34.855689Z","iopub.execute_input":"2024-06-06T06:48:34.856116Z","iopub.status.idle":"2024-06-06T06:48:35.004500Z","shell.execute_reply.started":"2024-06-06T06:48:34.856082Z","shell.execute_reply":"2024-06-06T06:48:35.003496Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/1370990263.py:4: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n  data['Date'] = pd.to_datetime(data['Date'])\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                               AMZN\nDate                               \n2014-06-06 00:00:00-04:00 -1.422434\n2014-06-09 00:00:00-04:00 -1.424503\n2014-06-10 00:00:00-04:00 -1.419822\n2014-06-11 00:00:00-04:00 -1.417162\n2014-06-12 00:00:00-04:00 -1.426018\n...                             ...\n2024-05-30 00:00:00-04:00  1.682151\n2024-05-31 00:00:00-04:00  1.627242\n2024-06-03 00:00:00-04:00  1.663466\n2024-06-04 00:00:00-04:00  1.682532\n2024-06-05 00:00:00-04:00  1.719519\n\n[2517 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AMZN</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2014-06-06 00:00:00-04:00</th>\n      <td>-1.422434</td>\n    </tr>\n    <tr>\n      <th>2014-06-09 00:00:00-04:00</th>\n      <td>-1.424503</td>\n    </tr>\n    <tr>\n      <th>2014-06-10 00:00:00-04:00</th>\n      <td>-1.419822</td>\n    </tr>\n    <tr>\n      <th>2014-06-11 00:00:00-04:00</th>\n      <td>-1.417162</td>\n    </tr>\n    <tr>\n      <th>2014-06-12 00:00:00-04:00</th>\n      <td>-1.426018</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2024-05-30 00:00:00-04:00</th>\n      <td>1.682151</td>\n    </tr>\n    <tr>\n      <th>2024-05-31 00:00:00-04:00</th>\n      <td>1.627242</td>\n    </tr>\n    <tr>\n      <th>2024-06-03 00:00:00-04:00</th>\n      <td>1.663466</td>\n    </tr>\n    <tr>\n      <th>2024-06-04 00:00:00-04:00</th>\n      <td>1.682532</td>\n    </tr>\n    <tr>\n      <th>2024-06-05 00:00:00-04:00</th>\n      <td>1.719519</td>\n    </tr>\n  </tbody>\n</table>\n<p>2517 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import r2_score\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense\n\n\n\n# data = pd.read_csv('/kaggle/input/stock-data/stock_data.csv')\n\n\n# data = data[['Date', 'Adj Close']]\n\n\n# data['Date'] = pd.to_datetime(data['Date'])\n# data.set_index('Date', inplace=True)\n\n\ntime_steps = 8\n\n# Create sequences of data for training\nsequences = []\ntargets = []\nfor i in range(len(data) - time_steps):\n    seq = data['AMZN'].values[i:i+time_steps]\n    label = data['AMZN'].values[i+time_steps]\n    sequences.append(seq)\n    targets.append(label)\n\nsequences = np.array(sequences)\ntargets = np.array(targets)\n\nscaler = MinMaxScaler(feature_range=(0, 1))\n\nsequences = scaler.fit_transform(sequences.reshape(-1, 1)).reshape(-1, time_steps, 1)\n\ntargets = targets.reshape(-1, 1)\ntargets = scaler.fit_transform(targets)\n\nsplit_index = int(0.8 * len(sequences))\nX_train, X_test = sequences[:split_index], sequences[split_index:]\ny_train, y_test = targets[:split_index], targets[split_index:]\n\nmodel = Sequential()\nmodel.add(LSTM(units=50, input_shape=(time_steps, 1)))\nmodel.add(Dense(units=1))\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\nmodel.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n\n\npredictions = model.predict(X_test)\n\npredictions = scaler.inverse_transform(predictions.reshape(-1, 1))\ny_test = scaler.inverse_transform(y_test)\n\n\nr2 = r2_score(y_test, predictions)\nprint(f'R^2 Score on Test Data: {r2}')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-06T06:49:31.616546Z","iopub.execute_input":"2024-06-06T06:49:31.616989Z","iopub.status.idle":"2024-06-06T06:49:41.775044Z","shell.execute_reply.started":"2024-06-06T06:49:31.616954Z","shell.execute_reply":"2024-06-06T06:49:41.773856Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0794 - val_loss: 9.3712e-04\nEpoch 2/10\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.6277e-04 - val_loss: 8.3508e-04\nEpoch 3/10\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.2473e-04 - val_loss: 8.1947e-04\nEpoch 4/10\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.4903e-04 - val_loss: 8.3199e-04\nEpoch 5/10\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.1870e-04 - val_loss: 8.6996e-04\nEpoch 6/10\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.2847e-04 - val_loss: 8.3028e-04\nEpoch 7/10\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.5015e-04 - val_loss: 9.0338e-04\nEpoch 8/10\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.0749e-04 - val_loss: 8.2101e-04\nEpoch 9/10\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.3574e-04 - val_loss: 8.2112e-04\nEpoch 10/10\n\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.7857e-04 - val_loss: 8.1220e-04\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\nR^2 Score on Test Data: 0.9697440827771338\n","output_type":"stream"}]}]}